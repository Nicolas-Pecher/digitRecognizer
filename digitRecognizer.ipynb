{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "train = pd.read_csv(\"./train.csv\")\n",
    "test = pd.read_csv(\"./test.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        0\n",
      "2        1\n",
      "3        4\n",
      "4        0\n",
      "        ..\n",
      "41995    0\n",
      "41996    1\n",
      "41997    7\n",
      "41998    6\n",
      "41999    9\n",
      "Name: label, Length: 42000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_train = train[\"label\"]\n",
    "print(label_train)\n",
    "# remove labels from the data\n",
    "target_train = train.drop(labels=[\"label\"], axis = 1)\n",
    "\n",
    "#normalize the data\n",
    "#CNN converg works faster on data bet-1 thanween 0 data between 0-255\n",
    "target_train = target_train / 255.0\n",
    "test = test / 255.0\n",
    "\n",
    "#reshape image data in 3D(28 width and height)\n",
    "target_train = target_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change one-hot encoding for label (3 = [0,0,0,1,0,0,0,0,0,0])\n",
    "label_train = to_categorical(label_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10% will be used for validation and the rest will be used to train the model\n",
    "target_train, target_val, label_train, label_val = train_test_split(target_train, label_train, test_size = 0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#example\n",
    "g = plt.imshow(target_train[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#combine features of Convolution layers.\n",
    "model.add(Flatten())\n",
    "#make artificial neural network with fully-connected dense layers.\n",
    "model.add(Dense(256, activation = \"relu\")) \n",
    "#randomly selected neurons are ignored during training\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = RMSprop(lr=0.001) , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37800 samples, validate on 4200 samples\n",
      "Epoch 1/3\n",
      " - 182s - loss: 0.2460 - accuracy: 0.9222 - val_loss: 0.0737 - val_accuracy: 0.9786\n",
      "Epoch 2/3\n",
      " - 180s - loss: 0.0737 - accuracy: 0.9781 - val_loss: 0.0401 - val_accuracy: 0.9883\n",
      "Epoch 3/3\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(target_train, label_train, batch_size = 86, epochs = 3, validation_data = (target_val, label_val), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict results\n",
    "results = model.predict(test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
